---
layout:            post
title:             "1. Hadoop2 세팅하기"
menutitle:         "1. Hadoop2 세팅하기"
category:          BigData
author:            geunyoung
cover:             /assets/mountain-alternative-cover.jpg
published:         true
language:          KO
comments:          true
---

## 들어가기 앞서...
  
 회사를 옮기게 되면서 빅데이터에 관한 팀에 TA 직무를 부여받아 Hadoop 관련 공부를 진행하고 있다. 도중에 헤매었던 부분이나 이 후에도 정리하면 자주 보게될 내용에 대해 정리를 진행한다. 
 
  
### 준비물 및 환경
  
 * VMWare 4대 (https://my.vmware.com/web/vmware/downloads 에서 VMware Workstation Player 다운로드) 
  
 * CentOS7 (http://mirror.kakao.com/centos/7.7.1908/isos/x86_64/ 에서 Centos-7-x86_64-DVD-1908.iso 다운로드)
  
 * Java1.7 (https://www.oracle.com/java/technologies/javase-downloads.html 에서 필요한 버전 다운로드)
  
 * Hadoop2.7 (http://www.apache.org/dyn/closer.cgi/hadoop/common 에서 필요한 버전 다운로드)
 
 * Protocol Buffer2.5.0 (https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz)
  
### 세팅에 앞서...
  
이론 정리는 추후에 더 정확히 이해하면 진행하겠다.

### 초기 세팅하기
  
1. 각 VMWare에 대해 고정 IP 설정 : 총 4대에 1대는 master, 3대는 slave로 활용될 것이다. 어떤 서버들이 연동되어 있는지 IP기반으로 세팅 할텐데 IP가 바뀌면 문제가 생길 것이다. (이번 장은 마스터 서버 1대에서만 실행할 것이지만 2장에 4대를 통한 완전분산시스템을 만들기 위해 미리 3대도 같이 세팅한다.)  
아래는 샘플이다.
```text
/etc/sysconfig/network-scripts에서
vi ifcfg-ens33(본인의 network명)
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
#BOOTPROTO="dhcp"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="5219bde3-2cbf-46d6-83e2-c2c6ac063c56"
DEVICE="ens33"
ONBOOT="yes"
BOOTPROTO="static"
IPADDR=192.168.93.128
NETMASK="255.255.255.0"
GATEWAY=192.168.93.2
DNS1=168.126.63.1
DNS2=168.126.63.2
와같이 생성
```
  
2. Hadoop에 사용할 계정 만들기  
샘플
```text
useradd hadoop(사용할 계정명)
passwd hadoop
```
  
3. 고정된 IP allias 만들어주기  
샘플
```text
cd /etc/hosts
192.168.93.128 server1
192.168.93.129 server2
192.168.93.130 server3
192.168.93.131 server4
```
  
4. UTF-8로 세팅되어 있는지 확인(echo $LANG)
  
5. 4대의 서버에 Java설치
```text
FTP툴을 활용하여 /usr/local에 자바.tar.gz 받은 후,
chmod 755 자바.tar.gz
tar xvfz 자바.tar.gz
심볼릭(바로가기)생성
ln -s 자바 java
/etc/profile에
export JAVA_HOME=usr/local/java
export PATH=$PATH:$JAVA_HOME/bin
export CLASS_PATH="."
추가후, 
프로필 적용
source /etc/profile
java -version을 통해 확인
```
  
6. 공개키 생성
```text
yum install openssh-server openssh-clients openssh-askpass -y
ssh-keygen -t rsa -b 4096 -C "본인이메일주소"
```
  
7. (/home/유저이름에 .ssh파일 생성된 것 확인후) 공개키 다른 서버에 전달( 이를 통해 server1에서도 ssh server2라는 형식으로 접속할 수 있으며, 하둡시스템간의 통신에서도 이상이 없다.
```text
ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@server3
ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@server3
ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@server3
```
  
8. /home/유저이름에 hadoop압축 풀기
```text
tar xvfz 하둠.tar.gz
```
  
9. Protobuf 설치 : Protobuf는 무엇이며 왜 설치를 할까? Protobuf는 구글에서 공개한 오픈소스 직렬화 라이브러이다. IT 기술이 발달되며 여러 시스템 간에 다양한 데이터 형식들(ex. 텍스트 포맷(XML, JSON), Binary 포맷)로 주고 받는다. 그 중 텍스트 포맷의 경우 가독성은 뛰어나지만 용량 대비 표현할 수 있는 양이 적어 바이너리 형식이 빅데이터 시스템에서 적합하다. 하지만 바이너리의 데이터는 복잡한 해독해야하는 번거루움이 있는데 이를 구글에서 오프소스화하여 공개하였다. 그것이 Protobuf이다.  
```text
wget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz를 통해 /usr/loacal/protobuf-2.5.0.tar.gz 다운
참고로 protobuf는 버전이 다르면 문제가 생긴다. 꼭 자신의 하둡버전에 맞는 protobuf버전을 설치하자
tar xvfz protobuf-2.5.0.tar.gz 압축풀기
./configure을 통해 설정 적용
make를 통해 컴파일
if c,c++ 컴파일러가 없다는 에러메세지가 뜬다면 root로 들어가서
yum install -y gcc
yum install -y gcc-c++
후, 다시 make 실행
완료되면 make install
완료되면 protoc --version을 통해 설치제대로 되었는지 확인
```
  
10. etc/hadoop/hadoop-env.sh 수정(이제부터 .sh, .xml 파일들을 수정할 텐데 기능 및 매뉴얼은 share/doc/hadoop/ 하위 디렉토리에 존재하니 참고하자.
```text
# Adding parameter about java
export JAVA_HOME=/usr/local/java1.7(심볼릭) #자바 Path가 잡혀 있다면 export JAVA_HOME=${JAVA_HOME}
export HADOOP_PID_DIR=/home/hadoop/hadoop-3.2.1/pids
```
  
11. 9번 파일있는 위치에서 master파일 수정(없을 시 생성)
```text
server1 (etc/hosts기준)
```
  
12. 9번 파일있는 위치에서 slaves파일 수정(없을 시 생성)
```text
server1 (etc/hosts기준)
```
  
13. 9번 파일있는 위치에서 core-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)

  
14. 9번 파일있는 위치에서 hdfs-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)

  
15. 9번 파일있는 위치에서 mapred-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)

  
16. 9번 파일있는 위치에서 yarn-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)

  
17. 실행되는지 확인
```text
./bin/hdfs namenode -format을 통해 네임노드 초기화(이 명령어는 모든 데이터를 초기화시키고 다시하니 운영중에는 절대 사용하면 안됨
(home/hadoop/hadoop-data/dfs/name이 초기화 된것을 볼 수 있다.)
./sbin/start-all.sh를 통해 실행
만약 웹인터페이스 외에도 맵리듀스 잡의 이력만 별도로 보고 싶다면 ./sbin/mr-jobhistory-daemin.sh start historyserver
만약 중지가 필요하면 ./sbin/stop-all
부분적인 중지는 ./sbin/stop-yarn.sh, ./sbin/stop-dfs.sh, ./sbin/mr-jobhistory-daemin.sh stop historyserver
```  
  
18. 실행 후, 관리 페이지 열어보기
```text
jsp
인터넷에서 본인IP:50070 검색하면 관리페이지를 볼 수 있으며,
본인IP:8088 은 얀 인터페이스를 제공하며,
19888번은 히스토리 인터페이스가 제공된다.
```

19. 예제 실행해보기
```text
해당 예제는 HDFS에 파일이 저장되고 얀을 기반으로 맵리듀스 잡이 실행되는 것을 보여주는 예제이다.
./bin/hdfs dfs -mkdir /user
./bin/hdfs dfs -mkdir /user/hadoop
./bin/hdfs dfs -mkdir /user/hadoop/conf
./bin/hdfs dfs -put etc/hadoop/hadoop-env.sh conf/
(hdfs 디렉토리 만들기)
./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount conf output
(map reduce 진행)
./bin/hdfs dfs -cat output/part-r-00000 | tail -5
(확인하기)
```

##### xml 샘플들
  
###### core-site.xml

```xml
<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://server1:9010</value>
</property>
</configuration>
```
  
###### hdfs-site.xml

```xml
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/home/hadoop/data/dfs/namenode</value>
</property>
<property>
<name>dfs.namenode.checkpoint.dir</name>
<value>/home/hadoop/data/dfs/namesecondary</value>
</property>
<property>
<name>dfs.namenode.data.dir</name>
<value>/home/hadoop/data/dfs/datanode</value>
</property>
<property>
<name>dfs.http.address</name>
<value>server1:50070</value>
</property>
<property>
<name>dfs.secondary.http.address</name>
<value>server1:50090</value>
</property>
</configuration>
```
  
###### mapred-site.xml
  
```xml
<configuration>
<property>
<name>mapred.framework.name</name>
<value>yarn</value>
</property>
</configuration>
``` 
  
###### yarn-site.xml

```xml
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanage.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>/home/hadoop/data/yarn/nm-local-dir</value>
  </property>
  <property>
    <name>yarn.resourcemanager.fs.state-store.uri</name>
    <value>/home/hadoop/data/yarn/system/rmstore</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hoastname</name>
    <value>server1</value>
  </property>
  <!-- Site specific YARN configuration properties -->
</configuration>
```
  
  
### 어려웠던 점...
  
 * ###### 어려움1
  >책을 보면서 공부를 진행하는 중인데 책이 Hadoop에 관한 책이여서 리눅스는 관련된 세팅과 작업들은 가볍게 언급하거나 알아서 세팅해야 했다. 이전 회사에서 어플리케이션 개발에 주업무였던 나는 리눅스 세팅에도 많은 시간이 투자되어 블로그에도 최대한 리눅스 관련 세팅도 작성하려 했다. 
  
 * ###### 어려움2
  >하둡은 현재 기준으로 하둡1,2,3이 나왔으며, 각 버전마다 환경 설정이나 파일들이 많이 달라진다. 현업(우리회사)에서는 2.X를 많이 사용하여 2버전을 설치 해놓고 1에 대한 설정 책을 읽다가 시간 허비를 많이 하였다. 부디 세팅 방법이나 책이 몇 버전인지 확인하고 시작하자!
