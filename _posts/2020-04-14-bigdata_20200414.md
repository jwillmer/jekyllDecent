---
layout:            post
title:             "주키퍼란 무엇인가"
menutitle:         "주키퍼란 무엇인가"
category:          BigData
author:            geunyoung
cover:             /assets/mountain-alternative-cover.jpg
published:         true
language:          KO
comments:          true
---
 
  
### 세팅에 앞서...
  
  최근에 빅데이터 시스템을 관리하게 되면서 주키퍼 시스템에 대해 정말 많이 마주치게 되었다. 처음에는 단순히 hadoop 시스템의 일부분으로만 알고 있었지만 Kafka와 쓰인다던지 Hbase로 쓰인다던지 많이 마주치게 되면서 주키퍼에 대한 개념과 설정방법을 공부해야 하겠다는 생각이 들었다.
    
### 주키퍼란 무엇인가
  
  주키퍼는(Zookeeper)는 Apache에서 만든 **분산 코디네이션 서비스**를 제공하는 오픈소스 프로젝트이다. 조금 더 쉽게 설명하자면 분산처리 시스템에서는 데이터를 분산시켜 여기저기서 저장을 하는데 어떤 데이터가 어디에 있는지에 대한 정보를 가지고 있는 시스템이 필요하다. 그 시스템이 바로 주키퍼이다.
  
### 주키퍼의 특징
  
  분산 시스템은 주로 엄청난 데이터를 처리한다. 그러기 위해선 처리 속도가 빨라야 한다. 그래서 주키퍼는 다중의 주키퍼 서버를 통해서 병렬식 처리를 한다.
  
 * ###### 특징1 : 병렬 처리를 한다.
 
 병렬처리를 하게 되면 또 다른 문제에 국면한다. 같은 작업을 2개의 서버에서 진행해버리는 문제가 있을 수 있고 건들고 있는 데이터를 다른 서버에서 건드는 문제가 발생 할 수 있다. 이 문제를 해결하기 위해 Locking and synchronization service를 제공한다. 즉, 건들고 있는 데이터나 처리하는 데이터에 대해서는 다른 서버가 못건들게 하는 방법이다.
 
 * ###### 특징2 : 동기화 서비스(Locking and synchronization service)
 
 그러면 서버들에게 '건들지 마라', '쓰고 있다', '너가 먼저 처리해라'라는 것을 판단해줄 무언가가 필요해진다. 또한, 서버들이 같은 데이터를 가지고 있어야한다(동기화). 그래서 주키퍼는 Follower와 Leader의 개념을 도입하였다. 아래의 그림을 통해 이해를 해보자.
   
<figure>
<img src="{{ "/media/img/Bigdata/zookeeper.PNG" | absolute_url }}" />
<figcaption>출처 :https://engkimbs.tistory.com/660 </figcaption>
</figure>
  
  
 
 * ###### ZooKeeper가 서버들을 동기화 시켜준다?
  

설정 관리(Configuration management) : 클러스터의 설정 정보를 최신으로 유지하기 위한 조율 시스템으로 사용됩니다.
클러스터 관리(Cluster management) : 클러스터의 서버가 추가되거나 제외될 때 그 정보를 클러스터 안 서버들이 공유하는 데 사용됩니다.
리더 채택(Leader selection) : 다중 어플리케이션 중에서 어떤 노드를 리더로 선출할 지를 정하는 로직을 만드는 데 사용됩니다. 주로 복제된 여러 노드 중 연산이 이루어지는 하나의 노드를 택하는 데 사용됩니다.
락, : 클러스터에 쓰기 연산이 빈번할 경우 경쟁상태에 들어갈 가능성이 커집니다. 이는 데이터 불일치를 발생시킵니다. 이 때, 클러스터 전체를 대상을 동기화해( 락을 검 ) 경쟁상태에 들어갈 경우를 사전에 방지합니다.


출처: https://engkimbs.tistory.com/660 [새로비]

과반수

출처: https://engkimbs.tistory.com/660 [새로비]
```text
systemctl disable firewalld
아래의 설정은 centOS 6부터는 사용되지 않는다고 하는데 오픈소스다보니 아래의 설정때문에 오류가 났던 적이 있다고 하여 설정하였다.
vi /etc/selinux/config
SELINUX=disabled로 수정
```
  
2. 시간 동기화 또한 이전 장에서 해야 했던 내용인데 클러스터링으로 사용할 시 제일 먼저 세팅해야하는 내용이다.
```text
yum install ntp -y
vi /etc/ntp.conf
이전 IP 주석 후,
server 0.asia.pool.ntp.org
server 1.asia.pool.ntp.org
server 2.asia.pool.ntp.org
server 3.asia.pool.ntp.org
systemctl start ntpd <--시작
systemctl enable ntpd <--재부팅시에도 시작하기
ntpq -p <-- 작동여부 확인
```
  
3. 이제 주키퍼를 다운 및 세팅할 것이다. 우선 1,2,3서버에 주키퍼용 계정 생성
```text
useradd zookeeper
passwd zookeeper
```
  
4. 1번 서버 주키퍼 계정으로 생성하여 /home/zookeeper의 위치에 주키퍼.tar.gz다운 
```text
wget http://apache.mirror.cdnetworks.com/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz
tar xvfz zookeeper-3.4.14.tar.gz
```
  
5. conf에 있는 zoo_sample.cfg를 활용하여 zoo.cfg작성
```text
cp conf/zoo_sample conf/zoo.cfg
vi conf/zoo.cfg
dataDir=/home/zookeeper/data로 수정
server.1=server1:2888:3888
server.2=server2:2888:3888
server.3=server3:2888:3888
추가
```
설명을 좀 덧붙이자면 dataDir은 주키퍼 스냅샷을 저장하는 경로, maxClientCnxns는 클리언트풀, maxSessisonTimeout은 세션시간, server.#는 서버들의 아이디이다. 2888은 주키퍼 리더에 접속하기 위한 포트, 3888은 리더 결정을 위한 포트이다.
  
6. 이제 설정한 아이디를 등록할 것이다.
```text
vi data/myid
1
```
  
7. zookeeper관련된 ssh키 설정 및 전달
```text
ssh-keygen -t rsa -b 4096 -C "본인이메일주소"
이름은 hadoop의 키와 다르게
ssh-copy-id -i /home/hadoop/.ssh/다르게만든이름.pub hadoop@server1
ssh-copy-id -i /home/hadoop/.ssh/다르게만든이름.pub hadoop@server2
ssh-copy-id -i /home/hadoop/.ssh/다르게만든이름.pub hadoop@server3
ssh-copy-id -i /home/hadoop/.ssh/다르게만든이름.pub hadoop@server4
정확히는 모르겠는데 하둡실행시 server1에서 server1으로 갈때도 ssh를 통해 가는 로직이 있나봄. 그래서 자기 자신의 키도 넣음
```

8. zookeeper 설정을 서버2,3에도 옮기는 작업 진행
```text
tar cvgz zookeeper.tar.gz zookeeper-3.4.14
scp zookeeper.tar.gz zookeeper@server2:/home/zookeeper
scp zookeeper.tar.gz zookeeper@server3:/home/zookeeper
ssh server2 "cd /home/zookeeper; tar xvfz zookeeper.tar.gz;mkdir data"
ssh server3 "cd /home/zookeeper; tar xvfz zookeeper.tar.gz;mkdir data"
```
  
9. 서버2,3에도 아이디 만들어 주기
```text
서버2에서
vi data/myid
2
서버3에서
vi data/myid
3
```
  
10. 서버1,2,3에 주키퍼 실행 및 상태 확인
```text
./bin/zkServer.sh start
./bin/zkServer.sh status
```
  
11. 이제 하둡세팅을 진행할 것이다. 우선 masters 삭제.  
스탠바이 네임노드가 보조네임노드의 역할을 할 수 있어서 필요가 없어진다.
  
12. slaves 수정
```text
#localhost
server1
server2
server3
server4
```
  
13. core-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)  
속성 정리를 해보자면  
dfs.namenode.name.dir = 네임 노드의 데이터 저장할 위치  
dfs.datanode.data.dir = 데이터 노드의 데이터 저장할 위치  
dfs.journalnode.edits.dir = 저널 노드의 데이터 저장할 위치  
dfs.nameservices = 네임 노드의 기능 설정. 일반적으로 클러스터링 세팅할 때 사용  
dfs.ha.namenodes.클러스터그룹명 = nameservices에 설정하려면 클러스터 명 설정  
dfs.namenode.rpc-address.클러스터그룹명.클러스터명 = rpc에 대한 클러스터명이 어디 서버와 포트를 사용할 것인지. rpc란 액티브, 스탠바이 관련 데이터인듯    
dfs.namenode.http-address.클러스터그룹명.클러스터명 = http에 대한 클러스터명이 어디 서버와 포트를 사용할 것인지. 웹 어드민 화면을 뿌릴 때 사용.
dfs.namenode.shared.edits.dir = 저널 노드에 대한 어디 서버와 포트하는지  
dfs.client.failover.proxy.provider.클러스터그룹명 = 액티브, 스탠바이 액션을 어떤 로직으로 돌릴지  
dfs.ha.fencing.methods = 액티브에서 스탠바이로 전환되면 그 노드는 접근 차단 되어야하는데 관련 로직에 대한 세팅  
dfs.ha.ssh.private-key-files = HA 왔다갔다 할때 어떤 키파일 사용할 것인지  
dfs.ha.automatic-failover.enabled = 장애발생시 액티브, 스탠바이 전환 할 것인지  
  
14. hdfs-site.xml 수정(Git 블로그 에러로 샘플 아래에 작성)
  
15. hadoop-env.sh, mapred-site,xml, yarn-env.sh, yarn-site.xml은 이전 1장와 같이 설정
  
16. 각 서버에 dfs.namenode.name.dir, dfs.datanode.data.dir, journalnode.edits.dir에 설정한 디렉토리 만들어 주기
  
17. 위의 세팅 server2,3,4에게 전달
```text
tar cvfz hadoop.tar.gz hadoop-2.7.7
scp hadoop.tar.gz hadoop@server2:/home/hadoop
scp hadoop.tar.gz hadoop@server3:/home/hadoop
scp hadoop.tar.gz hadoop@server4:/home/hadoop
ssh hadoop@server2 "cd /home/hadoop; tar xvfz hadoop.tar.gz;"
ssh hadoop@server3 "cd /home/hadoop; tar xvfz hadoop.tar.gz;"
ssh hadoop@server4 "cd /home/hadoop; tar xvfz hadoop.tar.gz;"
```
  
18. 주키퍼 초기화
```text
./bin/hdfs zkfc -formatZK
```
  
19. 저널노드 실행  
각 서버1,2,3에서 아래의 명령어 실행
```text
./sbin/hadoop-daemon.sh start journalnode
```
  
20. 네임노드 포맷
```text
./bin/hdfs namenode -format
```

21. 서버2의 네임노드 스탠바이로 설정  
서버2로 들어가서
```text
./bin/hdfs namenode -bootstrapStandby
```
  
22. 서버1,2로 가서 네임노드 실행
```text
./sbin/hadoop-daemon.sh start namenode
```

23. 서버1,2에서 주키퍼 컨트롤러 실행
```text
./sbin/hadoop-daemon.sh start zkfc
```
  
24. 데이터노드 실행
```text
책에서는 서버1 실행시키면 2,3,4 실행이 된다고 적혀있었지만 난 안되었음. 직접가서 2,3,4 실행 했고 문제없이 돌아가는 것 확인
./sbin/hadoop-daemon.sh start datanode
```
  
25. hdfs잘 작동하는지 디렉토리 만들며 테스트
```text
./sbin/hdfs dfs -ls /
./sbin/hdfs dfs -mkdir /user
./sbin/hdfs dfs -mkdir /user/hadoop
./sbin/hdfs dfs -mkdir /user/hadoop/conf
./sbin/hdfs dfs -put ../../../../hadoop-2.7.7/etc/hadoop/hadoop-env.sh /user/hadoop/conf/
./sbin/hdfs dfs -ls conf
```
  
26. 얀 클러스터 실행
```text
./sbin/start-yarn.sh
이것도 서버1 실행시키면 2,3 실행이 된다고 적혀있었지만 난 안되었음. 직접가서 2,3 실행 했고 문제없이 돌아가는 것 확인
```
  
27. 맵리듀스 잡을 위한 히스토이 서버 실행
```text
mr-jobhistory-daemon.sh start historyserver
```

28. jps를 통해 제대로 켜져있는지 확인
```text
서버1,2는 Jps, DFSZKFailoverController, Namenode, ResourceManager, JobHistoryServer, JournalNode, DataNode, NodeManager가 켜져있어야 하고, 서버3,4는 Jps, DataNode, NodeManager, JournalNode가 켜져 있어야한다.
```
  
29. 예제를 통한 정상 작동 확인
```text
./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount conf output
```


##### xml 샘플들
  
###### core-site.xml

```xml
<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://servers-cluster</value>
 </property>

 <property>
  <name>ha.zookeeper.quorum</name>
  <value>server1:2181,server2:2181,server3:2181</value>
 </property>
</configuration>
```
  
###### hdfs-site.xml

```xml
<configuration>
 <property>
  <name>dfs.namenode.name.dir</name>
  <value>/home/hadoop/data/dfs/namenode</value>
 </property>

 <property>
  <name>dfs.datanode.data.dir</name>
  <value>/home/hadoop/data/dfs/datanode</value>
 </property>

 <property>
  <name>dfs.journalnode.edits.dir</name>
  <value>/home/hadoop/data/dfs/journalnode</value>
 </property>

 <property>
  <name>dfs.nameservices</name>
  <value>servers-cluster</value>
 </property>

 <property>
  <name>dfs.ha.namenodes.servers-cluster</name>
  <value>nn1,nn2</value>
 </property>

 <property>
  <name>dfs.namenode.rpc-address.servers-cluster.nn1</name>
  <value>server1:8020</value>
 </property>

 <property>
  <name>dfs.namenode.rpc-address.servers-cluster.nn2</name>
  <value>server2:8020</value>
 </property>

 <property>
  <name>dfs.namenode.http-address.servers-cluster.nn1</name>
  <value>server1:50070</value>
 </property>

 <property>
  <name>dfs.namenode.http-address.servers-cluster.nn2</name>
  <value>server2:5070</value>
 </property>

 <property>
  <name>dfs.namenode.shared.edits.dir</name>
  <value>qjournal://server1:8485;server2:8485;server3:8485/servers-cluster</value>
 </property>

 <property>
  <name>dfs.client.failover.proxy.provider.servers-cluster</name>
  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
 </property>

 <property>
  <name>dfs.ha.fencing.methods</name>
  <value>sshfence</value>
 </property>

 <property>
  <name>dfs.ha.ssh.private-key-files</name>
  <value>/home/hadoop/.ssh/id_rsa</value>
 </property>


 <property>
  <name>dfs.ha.automatic-failover.enabled</name>
  <value>true</value>
 </property>
</configuration>
```
  
  
### 잘못 알고 있었던 정보 / 헷갈려던 부분
  
 * ###### ZooKeeper가 서버들을 동기화 시켜준다?
  >책을 보면서 공부를 진행하는 중인데 책이 Hadoop에 관한 책이여서 리눅스는 관련된 세팅과 작업들은 가볍게 언급하거나 알아서 세팅해야 했다. 이전 회사에서 어플리케이션 개발에 주업무였던 나는 리눅스 세팅에도 많은 시간이 투자되어 블로그에도 최대한 리눅스 관련 세팅도 작성하려 했다.

 * ###### Kafka사버와 브로커는 동일 개념?
  >책을 보면서 공부를 진행하는 중인데 책이 Hadoop에 관한 책이여서 리눅스는 관련된 세팅과 작업들은 가볍게 언급하거나 알아서 세팅해야 했다. 이전 회사에서 어플리케이션 개발에 주업무였던 나는 리눅스 세팅에도 많은 시간이 투자되어 블로그에도 최대한 리눅스 관련 세팅도 작성하려 했다.

### 참고한 사이트 및 이미지 링크
  
 * https://engkimbs.tistory.com/660
